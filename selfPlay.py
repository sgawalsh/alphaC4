import tensorflow as tf, mc, config, engine, pdb, random, pickle, os, NNfunctions, numpy, datetime, sys
from tqdm import tqdm
from head2Head import head2Head
from keras.utils import np_utils

class gameSet(): # class used to track training game results
	def __init__(self):
		self.gameBoards = [] # contains board-move pairs generated by champion NN
		self.hasWinner = False
		self.redWins = False
		
def createTrainingSet(modelName): # create config.trainingSetSize games by champion using MCTS against self, for each board store move probs, and eventual winner, append data to library, deleting old data
	try:
		trainingSet = pickle.load(open(modelName + "\\trainingSet", "rb"))
	except FileNotFoundError:
		trainingSet = []
	
	currSet = gameSet()
	champVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	champPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	print("Creating new training samples...")
	
	for _ in tqdm(range(config.minTrainingSetSize - len(trainingSet) if len(trainingSet) < config.minTrainingSetSize and (config.minTrainingSetSize - len(trainingSet)) > config.trainingSetSize else config.trainingSetSize)):
		currBoard = engine.board()
		isRedTurn = (_ % 2) == 0
		while True:
			myTree = mc.monteTree(currBoard, isRedTurn, champPol, champVal)
			for _2 in range(config.trainingRecursionCount): # build tree
				myTree.nnSelectRec(myTree.root)
			currSet.gameBoards.append([myTree.root.board, myTree.root.isRedTurn, myTree.getMoveProbs()])
			currBoard, rowNum, colNum = myTree.makeMove()
			#boardMovePair.append(myTree.root.colNum) # associate move with prev board and player turn
			if currBoard.checkWin(rowNum, colNum, myTree.root.isRedTurn): # check winner, assign appropriate values to gameset
				currSet.hasWinner = True
				currSet.redWins = myTree.root.isRedTurn
				trainingSet.append(currSet)
				currSet = gameSet()
				break
			elif currBoard.checkDraw():
				trainingSet.append(currSet)
				currSet = gameSet()
				break
			isRedTurn = not isRedTurn
	# slice oldest games, pickle training set
	pickle.dump(trainingSet[-config.fullTrainingSetSize:], open(modelName + "\\trainingSet", "w+b"))
	
def createTrainingSetExploration(modelName): # create config.trainingSetSize games by champion using MCTS against self, uses temperature variable to manage exploratory play, for each board store move probs, and eventual winner, append data to library, deleting old data
	try:
		trainingSet = pickle.load(open(modelName + "\\trainingSet", "rb"))
	except FileNotFoundError:
		trainingSet = []
	
	currSet = gameSet()
	champVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	champPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	print("Creating new training samples...")
	
	for _ in tqdm(range(config.minTrainingSetSize - len(trainingSet) if len(trainingSet) < config.minTrainingSetSize and (config.minTrainingSetSize - len(trainingSet)) > config.trainingSetSize else config.trainingSetSize)):
		currBoard = engine.board()
		isRedTurn = (_ % 2) == 0
		turnCount = 0
		while True:
			myTree = mc.monteTree(currBoard, isRedTurn, champPol, champVal)
			for _2 in range(config.trainingRecursionCount): # build tree
				myTree.nnSelectRec(myTree.root)
			temp = mc.monteTree.turnCountToTemp(turnCount)
			if temp < 1:
				currBoard, rowNum, colNum = myTree.exploratoryMove(temp)
			else:
				currBoard, rowNum, colNum = myTree.makeMove()
			currSet.gameBoards.append([myTree.root.board, myTree.root.isRedTurn, myTree.getMoveProbs()])
			if currBoard.checkWin(rowNum, colNum, myTree.root.isRedTurn): # check winner, assign appropriate values to gameset
				currSet.hasWinner = True
				currSet.redWins = myTree.root.isRedTurn
				trainingSet.append(currSet)
				currSet = gameSet()
				break
			elif currBoard.checkDraw():
				trainingSet.append(currSet)
				currSet = gameSet()
				break
			isRedTurn = not isRedTurn
			turnCount += 1
	# slice oldest games, pickle training set
	pickle.dump(trainingSet[-config.fullTrainingSetSize:], open(modelName + "\\trainingSet", "w+b"))
	
def createChallengerPair(modelName): # use sample board positions from library, use mcts to train current champion NN to create challenger NN and VNN
	print("Creating new challenger...")
	boardList, boardMoves, boardResults = loadData(pickle.load(open(modelName + "\\trainingSet", "rb")), config.challengerSamples)
	
	boardList = numpy.array(NNfunctions.boardArrayListToInputs(boardList))
	trainVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	trainPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	#trainPol.fit(boardList, np_utils.to_categorical(boardMoves, 7), epochs = config.challengerEpochs, batch_size = int(config.challengerSamples * config.batchSizeRatio)) # train policy on board-move pairs
	print("Fitting Policy NN...")
	trainPol.fit(boardList, boardMoves, epochs = config.challengerEpochs, batch_size = int(config.challengerSamples * config.batchSizeRatio))
	print("Fitting Value NN...")
	trainVal.fit(boardList, boardResults, epochs = config.challengerEpochs, batch_size = int(config.challengerSamples * config.batchSizeRatio)) # train value on game results
	
	trainVal.save(modelName + "//the_value_challenger")
	trainPol.save(modelName + "//the_policy_challenger")
	print("Challenger ready and primed!")
	
def modelShowdown(modelName): # play config.showDownSize games using mcts, if challenger wins config.winRatio challenger becomes new champion
	champVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	champPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	challVal = tf.keras.models.load_model(modelName + "\\the_value_challenger")
	challPol = tf.keras.models.load_model(modelName + "\\the_policy_challenger")
	
	champWins, challWins, drawCount = head2Head(True, "Champion", "Challenger", champVal, champPol, challVal, challPol, config.showDownSize, config.trainingRecursionCount)
	
	if ((challWins / champWins) > config.winRatio if champWins else True): # save previous champions to folder
		print("New champion!!")
		prevChampPath = modelName + "\\prevChamp"
		
		if not os.path.exists(prevChampPath):
			os.makedirs(prevChampPath)
		
		champArray = [f for f in os.listdir(prevChampPath) if os.path.isfile(os.path.join(prevChampPath, f)) and f[0:9] == "prevChamp"]
		
		champArray = sorted(champArray, key=lambda x: int(x[12:]))
		
		while len(champArray) > (config.champArrayLength * 2):
			os.remove(join(prevChampPath, champArray[0]))
			del champArray[0]
		
		champNum = (str(int(champArray[len(champArray) - 1][12:]) + 1) if champArray else "1")
		
		champVal.save(prevChampPath + "//prevChampVal" + champNum)
		champPol.save(prevChampPath + "//prevChampPol" + champNum)
		
		challVal.save(modelName + "//the_value_champ")
		challPol.save(modelName + "//the_policy_champ")
		
def loadOrCreateModel(specs): # User can select existing model, or create new one
	folderList = os.listdir(os.path.dirname(os.path.realpath(__file__)) + "\\models")
	if folderList:
		print("Models:")
		
		for i, folder in enumerate(folderList):
			print(str(i + 1) + ". " + folder)
			
		while True:
			try:
				modelInd = int(input(("Which model do you want to load? Select number or press '0' to create a new model. \n> ")))
				if modelInd > len(folderList) or modelInd < 0:
					print("Value out of range")
				else:
					break
			except ValueError:
				print("Which model do you want to load? Select number or press '0' to create a new model. \n> ")
		
		if modelInd:
			getSummary(os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1])
			if not os.path.exists(os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1] + specs):
				if config.getResponseFromList("This model has not been initialized for your current specs. Would you like to clone the existing model structure?", ['y','n']) == 'y':
					cloneModel(os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1], specs)
					return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1] + specs
				else:
					exit()
			else:
				return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1] + specs
		else:
			print("Creating new model")
			while True:
				data = input("What do you want to call the model?\n> ")
				if data:
					if data not in folderList:
						if "_" not in data:
							createModel(data, specs)
							return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + data + specs
						else:
							print("No underscores please.")
					else:
						print("A model with that name already exists.")
			
	else:
		print("No models exist")
		while True:
			data = input("What do you want to call the model?\n> ")
			if data:
				createModel(data, specs)
				return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + data + specs

def cloneModel(modelPath, specs): # clone an existing model to be used under different config specs
	modelName = modelPath + "\\" + os.listdir(modelPath)[0]
	valModel = tf.keras.models.clone_model(tf.keras.models.load_model(modelName + "\\the_value_champ"))
	valModel.compile(optimizer = config.optimizer, loss = config.valLoss, metrics = config.metrics)
	polModel = tf.keras.models.clone_model(tf.keras.models.load_model(modelName + "\\the_policy_champ"))
	polModel.compile(optimizer = config.optimizer, loss = config.polLoss, metrics = config.metrics)
	
	if not os.path.exists(modelPath + specs):
		os.makedirs(modelPath + specs)
		
	valModel.save(modelPath + specs + "\\the_value_champ")
	polModel.save(modelPath + specs + "\\the_policy_champ")
	
def createModel(modelName, specs): # User names new model and specifies shape
	os.mkdir("models\\" + modelName)
	os.mkdir("models\\" + modelName + specs)
	print("Creating value model...")
	model = tf.keras.models.Sequential()
	hasSimpleAsLast = [False]
	addLayer(model, (6,7,3), hasSimpleAsLast)
	while True:
		userChoice = config.getResponseFromList("Would you like to add another layer?", ('y', 'n'))
		if userChoice == 'y':
			try:
				addLayer(model, model.layers[len(model.layers) - 1].output_shape[1:], hasSimpleAsLast)
			except AttributeError:
				addLayer(model, model.layers[len(model.layers) - 1].units, hasSimpleAsLast)
		else:
			break

	if not hasSimpleAsLast[0]:
		model.add(tf.keras.layers.Flatten())
	model.add(tf.keras.layers.Dense(3, activation = tf.nn.softmax)) # 3 category value model
	print("Here's the value model:")
	model.compile(optimizer = config.optimizer, loss = config.valLoss, metrics = config.metrics)
	model.summary()
	model.save("models//" + modelName + specs + "//the_value_champ")
	
	print("Creating policy model...")
	model = tf.keras.models.Sequential()
	hasSimpleAsLast = [False]
	addLayer(model, (6,7,3), hasSimpleAsLast)
	while True:
		userChoice = config.getResponseFromList("Would you like to add another layer?", ('y', 'n'))
		if userChoice == 'y':
			try:
				addLayer(model, model.layers[len(model.layers) - 1].output_shape[1:], hasSimpleAsLast)
			except AttributeError:
				addLayer(model, model.layers[len(model.layers) - 1].units, hasSimpleAsLast)
		else:
			break

	if not hasSimpleAsLast[0]:
		model.add(tf.keras.layers.Flatten())
	model.add(tf.keras.layers.Dense(7, activation = tf.nn.softmax)) # policy value model
	print("Here's the policy model:")
	model.summary()
	#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
	model.compile(optimizer = config.optimizer, loss = config.polLoss, metrics = config.metrics)
	model.save("models//" + modelName + specs + "//the_policy_champ")
		
def loadModel(): # User selects model, specs, selected model path is returned
	folderList = os.listdir(os.path.dirname(os.path.realpath(__file__)) + "\\models")
	if folderList:
		print("Models:")
			
		while True:
			for i, folder in enumerate(folderList):
				print(str(i + 1) + ". " + folder)
			try:
				modelInd = int(input(("Which model do you want to load?\n> ")))
				if modelInd > len(folderList) or modelInd <= 0:
					print("Value out of range")
				else:
					break
			except ValueError:
				print("Which model do you want to load?\n> ")
		
		if modelInd:
			specList = os.listdir(os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1])
			while True:
				for i, folder in enumerate(specList):
					print(str(i + 1) + ". " + folder)
				try:
					specInd = int(input(("Which model specs do you want to load?\n> ")))
					if specInd > len(specList) or specInd <= 0:
						print("Value out of range")
					else:
						specArray = specList[specInd - 1].split("_")
						const = int(specArray[3])
						if specArray[4]:
							const = float(const + float("." + specArray[4]))
						break
				except ValueError:
					print("Which model specs do you want to load?\n> ")
			return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1] + "\\" + specList[specInd - 1], int(specArray[1]), const
	
def addLayer(model, shape, hasSimpleAsLast): # Adds layer to model currently being created by the user
	userChoice = config.getResponseFromList("Would you like to make a convolutional, or simple layer?", ('c', 's'))
	if userChoice == 'c':
		hasSimpleAsLast[0] = False
		filterNum = config.getIntResponse("How many filters should this layer have?")
		filterDimVert = config.getIntResponse("What should the height of the filter be?")
		filterDimHori = config.getIntResponse("What should the width of the filter be?")
		paddingChoice = config.getResponseFromList("Should the padding type be same (zero padded), or valid (non-zero padded)?", ('s', 'v'))
		model.add(tf.keras.layers.Conv2D(filterNum, (filterDimVert, filterDimHori), input_shape = shape, padding = "same" if paddingChoice == 's' else "valid"))
		model.add(tf.keras.layers.BatchNormalization())
		model.add(tf.keras.layers.Activation(config.getResponseFromList("Which activation function should the layer use?", ('elu', 'relu', 'selu', 'sigmoid', 'softplus', 'softmax', 'softsign', 'tanh'))))
	elif userChoice == 's':
		activationDict = {
			"el" : tf.nn.elu,
			"rl" : tf.nn.relu,
			"sl" : tf.nn.selu,
			"sg" : tf.nn.sigmoid,
			"sm" : tf.nn.softmax,
			"sp" : tf.nn.softplus,
			"ss" : tf.nn.softsign,
			"tn" : tf.nn.tanh
		}
		nuerons = config.getIntResponse("How many neurons should this layer have?")
		layerActivation = activationDict[config.getResponseFromList("What activation function should the layer use? elu, relu, selu, sigmoid, softplus, softmax, softsign, or tanh?", ('el', 'rl', 'sl', 'sg', 'sm', 'sp', 'ss', 'tn'))]
		if not hasSimpleAsLast[0]:
			model.add(tf.keras.layers.Flatten(input_shape=shape))
		model.add(tf.keras.layers.Dense(nuerons, activation = layerActivation))
		hasSimpleAsLast[0] = True

def autoSelfplay(): # user loads model, function cycles updating training set, creating challenger, and performing showdowns
	modelPath = loadOrCreateModel("\\Rec_" + str(config.trainingRecursionCount) + "_Const_" + str(config.MCTSexploration)[:10].replace(".", "_"))

	while True:
		createTrainingSetExploration(modelPath)
		createChallengerPair(modelPath)
		modelShowdown(modelPath)
		
def generationTournament(): # Performs a round robin tournament in which each previous saved champion and current champion play eachother as many times as is stored in the config.selfTournamentShowDownSize variable, shows results and gives user option to save results
	modelPath, rec, const = loadModel()
	#config.MCTSexploration = const
	
	if not os.path.isdir(modelPath + "\\prevChamp\\"):
		print("No previous champions exist")
		return
	champArrayVal = sorted([f for f in os.listdir(modelPath + "\\prevChamp\\") if os.path.isfile(os.path.join(modelPath + "\\prevChamp\\", f)) and f[0:12] == "prevChampVal"], key=lambda x: int(x[12:]))
	champArrayPol = sorted([f for f in os.listdir(modelPath + "\\prevChamp\\") if os.path.isfile(os.path.join(modelPath + "\\prevChamp\\", f)) and f[0:12] == "prevChampPol"], key=lambda x: int(x[12:]))
	
	try:
		if len(champArrayPol) != len(champArrayVal):
			raise Exception("Unequal count of Value and Policy Neural Nets")
		else:
			for i in range(len(champArrayVal)):
				if champArrayVal[i][12:] != champArrayPol[i][12:]:
					raise Exception("Neural nets are missing from policy or value arrays")
			if len(champArrayPol) == 0:
				raise Exception("No previous champions exist.")
	except Exception as e:
		print("Error: " + str(e))
		sys.exit()
	
	tournDict = {}
	print("Beginning Tournament!")
	
	for i in range(len(champArrayVal)):
		valNN1 = tf.keras.models.load_model(modelPath + "\\prevChamp\\prevChampVal" + str(i + 1))
		polNN1 = tf.keras.models.load_model(modelPath + "\\prevChamp\\prevChampPol" + str(i + 1))
		if i < len(champArrayVal):
			for j in range(i + 1, len(champArrayVal)):
				print(str(i + 1) + " vs " + str(j + 1))
				valNN2 = tf.keras.models.load_model(modelPath + "\\prevChamp\\prevChampVal" + str(j + 1))
				polNN2 = tf.keras.models.load_model(modelPath + "\\prevChamp\\prevChampPol" + str(j + 1))
				
				nn1Wins, nn2Wins, drawCount = head2Head(False, "Gen " + str(i + 1), "Gen " + str(j + 1), valNN1, polNN1, valNN2, polNN2, config.selfTournamentShowDownSize, rec, custConst1 = (const if str(const)[:9] != str(config.MCTSexploration)[:9] else None))
				
				tournDict[str(i + 1) + "vs" + str(j + 1)] = {"nn1Wins": nn1Wins, "nn2Wins": nn2Wins, "Draws": drawCount}
		
		print(str(i + 1) + " vs champ") 
		valNN2 = tf.keras.models.load_model(modelPath + "\\the_value_champ")
		polNN2 = tf.keras.models.load_model(modelPath + "\\the_policy_champ")
		
		nn1Wins, nn2Wins, drawCount = head2Head(False, "Gen " + str(i + 1), "Champ", valNN1, polNN1, valNN2, polNN2, config.selfTournamentShowDownSize, rec)
		tournDict[str(i + 1) + "vsChamp"] = {"nn1Wins": nn1Wins, "nn2Wins": nn2Wins, "Draws": drawCount}
	
	print("Completed Tournament! Final Results: ")
	for key, val in tournDict.items():
		print(key + ": " + str(val))
		
	if config.getResponseFromList("Do you wish to save this result?", ('y','n')) == 'y':
		if not os.path.exists(modelPath + "\\selfTournamentResults\\"):
			os.makedirs(modelPath + "\\selfTournamentResults\\")
		pickle.dump(tournDict, open(modelPath + "\\selfTournamentResults\\" + "rec_" + str(rec) + "_const_" + str(const) + "_bo" + str(config.selfTournamentShowDownSize).replace(".", "_") + "_" + datetime.datetime.now().strftime("%Y-%m-%d-%H-%M"), "wb"))
	
def loadTournamentResults(): # User can select any existing selfplay tournament results
	resultsPath = loadModel()[0] + "\\selfTournamentResults\\"
	if not os.path.exists(resultsPath):
		print("No tournament results exist")
		return
	else:
		resultList = os.listdir(resultsPath)
		for i, fileName in enumerate(resultList):
			print(str(i + 1) + ". " + fileName)
		
		while True:
			try:
				modelInd = int(input(("Which result do you want to load?\n> ")))
				if modelInd > len(resultList) or modelInd <= 0:
					print("Value out of range.")
				else:
					break
			except ValueError:
				print("Try typing a number.")
		
		for key, val in pickle.load(open(resultsPath + resultList[modelInd - 1], "rb")).items():
			print(key + ": " + str(val))
			
def testCreateChallengerPair(modelName): # troubleshooter used for debugging
	trainingSet = pickle.load(open(modelName + "\\trainingSet", "rb"))
	
	boardList, boardMoves, boardResults = loadData(trainingSet, config.challengerSamples)
	boardList_test, boardMoves_test, boardResults_test = loadData(trainingSet, 1000)
	
	boardInputs = numpy.array(NNfunctions.boardArrayListToInputs(boardList))
	boardInputs_test = numpy.array(NNfunctions.boardArrayListToInputs(boardList_test))
	champVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	champPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	trainVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	trainPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	# for i in range(len(boardList_test)):
		# testBoard = engine.board()
		# testBoard.board = boardList_test[i][0]
		# testBoard.printBoard()
		# print(["redTurn" if boardList_test[i][1] else "yellowTurn", boardMoves_test[i], boardResults_test[i]])
	
	trainPol.evaluate(boardInputs_test, boardMoves_test)
	trainVal.evaluate(boardInputs_test, boardResults_test)
	
	trainPol.fit(boardInputs, boardMoves, epochs = config.challengerEpochs, batch_size = int(config.challengerSamples * config.batchSizeRatio)) # train policy on board-move pairs
	trainVal.fit(boardInputs, boardResults, epochs = config.challengerEpochs, batch_size = int(config.challengerSamples * config.batchSizeRatio)) # train value on game results
	
	# head2Head(False, "champ", "chall", champVal, champPol, champVal, champPol, 100, 100)
	trainPol.evaluate(boardInputs_test, boardMoves_test)
	trainVal.evaluate(boardInputs_test, boardResults_test)
	
	champPol.evaluate(boardInputs_test, boardMoves_test)
	champVal.evaluate(boardInputs_test, boardResults_test)
	
	# trainVal.save(modelName + "//the_value_challenger")
	# trainPol.save(modelName + "//the_policy_challenger")
	print("TEST OVER")
	
def loadData(trainingSet, samples):
	boardList = []
	boardMoves = []
	boardResults = []
	
	for _ in tqdm(range(samples)):# get random game and board from training set, for each, append board state, player turn, associated move, and game result
		set = random.choice(trainingSet)
		board = random.choice(set.gameBoards)
		boardList.append([board[0].board, board[1]]) # board state and player turn
		boardMoves.append(board[2]) # board move
		if set.hasWinner: # game result, 2 for win for current player, 0 for loss
			boardResults.append(2 if set.redWins == board[1] else 0)
		else: # draw
			boardResults.append(1)
			
	return boardList, numpy.array(boardMoves), boardResults
	
def getSummary(folderName): # Gives structure summaries for selected model
	folderName += "\\" + os.listdir(folderName)[0]
	
	model = tf.keras.models.load_model(folderName + "\\the_value_champ")
	print("Here's the Value model structure: ")
	model.summary()
	model = tf.keras.models.load_model(folderName + "\\the_policy_champ")
	print("Here's the Policy model structure: ")
	model.summary()