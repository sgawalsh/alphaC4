import tensorflow as tf, mc, config, engine, pdb, random, _pickle, os, NNfunctions, numpy, datetime
from tqdm import tqdm
from head2Head import head2Head
from keras.utils import np_utils

class gameSet(): # class used to track training game results
	def __init__(self, gameID = 0):
		self.gameID = gameID
		self.gameBoards = [] # contains board-move pairs generated by champion NN
		self.hasWinner = False
		self.redWins = False
		
def createTrainingSet(modelName, firstRun = False): # create config.trainingSetSize games by champion using MCTS against self, for each board store move probs, and eventual winner, append data to library, deleting old data
	try:
		trainingSet = _pickle.load(open(modelName + "\\trainingData\\trainingSet", "rb"))
		gameID = trainingSet[len(trainingSet) - 1].gameID
		gameID = gameID if gameID < config.fullTrainingSetSize else 0
	except FileNotFoundError:
		gameID = 0
		trainingSet = []
		if not os.path.exists(modelName + "\\trainingData"):
			os.makedirs(modelName + "\\trainingData")
	
	currSet = gameSet(gameID + 1)
	champVal = tf.keras.models.load_model(modelName + "\\the_value_champ")
	champPol = tf.keras.models.load_model(modelName + "\\the_policy_champ")
	
	print("Creating new training samples...")
	
	for _ in tqdm(range((int(config.challengerSamples / 5)) if firstRun else config.trainingSetSize)):
		myTree = mc.monteTree(engine.board(), (_ % 2) == 0, champPol, champVal)
		while True:
			boardMovePair = [myTree.root.board, myTree.root.isRedTurn]
			for _2 in range(config.trainingRecursionCount): # build tree
				myTree.nnSelectRec(myTree.root)
			myTree.makeMove(True) # set root to next move
			boardMovePair.append(myTree.root.colNum) # associate move with prev board and player turn
			currSet.gameBoards.append(boardMovePair)
			if myTree.root.board.checkWin(myTree.root.rowNum, myTree.root.colNum, not myTree.root.isRedTurn): # check winner, assign appropriate values to gameset
				#myTree.root.board.printBoard()
				currSet.hasWinner = True
				currSet.redWins = not myTree.root.isRedTurn
				trainingSet.append(currSet)
				currSet = gameSet(currSet.gameID + 1)
				break
			elif myTree.root.board.checkDraw():
				trainingSet.append(currSet)
				currSet = gameSet(currSet.gameID + 1)
				break
	# slice oldest games, pickle training set
	_pickle.dump(trainingSet[-config.fullTrainingSetSize:], open(modelName + "\\trainingData\\trainingSet", "w+b"))
	
	print("Training samples updated.")

def createChallengerPair(modelName): # use sample board positions from library, use mcts to train current champion NN to create challenger NN and VNN
	trainingSet = _pickle.load(open(modelName + "\\trainingData\\trainingSet", "rb"))
	boardList = []
	boardMoves = []
	boardResults = []
	
	print("Creating new challenger...")
	
	for _ in tqdm(range(config.challengerSamples)):# get random game and board from training set, for each, append board state, player turn, associated move, and game result
		set = random.choice(trainingSet)
		board = random.choice(set.gameBoards)
		boardList.append([board[0].board, board[1]]) # board state and player turn
		boardMoves.append(board[2]) # board move
		if set.hasWinner: # game result, 2 for win for current player, 0 for loss
			boardResults.append(2 if set.redWins == board[1] else 0)
		else: # draw
			boardResults.append(1)
	
	boardList = numpy.array(NNfunctions.boardArrayListToInputs(boardList))
	trainVal = tf.keras.models.load_model(modelName + "/the_value_champ")
	trainPol = tf.keras.models.load_model(modelName + "/the_policy_champ")
	
	trainPol.fit(boardList, np_utils.to_categorical(boardMoves, 7), epochs = config.challengerEpochs, batch_size = 500) # train policy on board-move pairs
	trainVal.fit(boardList, np_utils.to_categorical(boardResults, 3), epochs = config.challengerEpochs, batch_size = 500) # train value on game results
	
	trainVal.save(modelName + "//the_value_challenger")
	trainPol.save(modelName + "//the_policy_challenger")
	print("Challenger ready and primed!")
	
def modelShowdown(modelName): # play config.showDownSize games using mcts, if challenger wins config.winRatio challenger becomes new champion
	champVal = tf.keras.models.load_model(modelName + "/the_value_champ")
	challVal = tf.keras.models.load_model(modelName + "/the_value_challenger")
	champPol = tf.keras.models.load_model(modelName + "/the_policy_champ")
	challPol = tf.keras.models.load_model(modelName + "/the_policy_challenger")
	
	champWins, challWins, drawCount = head2Head(True, "Champion", "Challenger", champVal, champPol, challVal, challPol, config.showDownSize, config.trainingRecursionCount)
	
	if (challWins / champWins) > config.winRatio:
		print("New champion!!")
		#save previous champions to folder
				
		champArray = [f for f in os.listdir(modelName) if os.path.isfile(os.path.join(modelName, f)) and f[0:9] == "prevChamp"]
		
		champArray = sorted(champArray, key=lambda x: int(x[12:]))
		
		while len(champArray) > (config.champArrayLength * 2):
			os.remove(join(modelName, champArray[0]))
			del champArray[0]
		
		champNum = (str(int(champArray[len(champArray) - 1][12:]) + 1) if champArray else "1")
		
		champVal.save(modelName + "//prevChampVal" + champNum)
		champPol.save(modelName + "//prevChampPol" + champNum)
		
		challVal.save(modelName + "//the_value_champ")
		challPol.save(modelName + "//the_policy_champ")
		
def loadOrCreateModel(): # User can select existing model, or create new one
	folderList = os.listdir(os.path.dirname(os.path.realpath(__file__)) + "\\models")
	if folderList:
		print("Models:")
		
		for i, folder in enumerate(folderList):
			print(str(i + 1) + ". " + folder)
			
		while True:
			try:
				modelInd = int(input(("Which model do you want to load? Select number or press '0' to create a new model. \n> ")))
				if modelInd > len(folderList) or modelInd < 0:
					print("Value out of range")
				else:
					break
			except ValueError:
				print("Which model do you want to load? Select number or press '0' to create a new model. \n> ")
		
		if modelInd:
			return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1]
		else:
			print("Creating new model")
			while True:
				data = input("What do you want to call the model?\n> ")
				if data:
					if data not in folderList:
						createModel(data)
						return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + data
					else:
						print("A model with that name already exists.")
			
	else:
		print("No models exist")
		while True:
			data = input("What do you want to call the model?\n> ")
			if data:
				createModel(data)
				return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + data

def createModel(modelName): # User names new model and specifies shape
	os.mkdir("models\\" + modelName)
	print("Creating value model")
	model = tf.keras.models.Sequential()
	hasSimpleAsLast = [False]
	addLayer(model, (6,7,3), hasSimpleAsLast)
	while True:
		userChoice = config.getResponseFromList("Would you like to add another layer?", ('y', 'n'))
		if userChoice == 'y':
			try:
				addLayer(model, model.layers[len(model.layers) - 1].output_shape[1:], hasSimpleAsLast)
			except AttributeError:
				addLayer(model, model.layers[len(model.layers) - 1].units, hasSimpleAsLast)
		else:
			break

	if not hasSimpleAsLast[0]:
		model.add(tf.keras.layers.Flatten())
	model.add(tf.keras.layers.Dense(3, activation = tf.nn.softmax))#3 category value model
	print("Here's the value model:")
	model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
	model.summary()
	model.save("models//" + modelName + "//the_value_champ")
	
	print("Creating policy model")
	model = tf.keras.models.Sequential()
	hasSimpleAsLast = [False]
	addLayer(model, (6,7,3), hasSimpleAsLast)
	while True:
		userChoice = config.getResponseFromList("Would you like to add another layer?", ('y', 'n'))
		if userChoice == 'y':
			try:
				addLayer(model, model.layers[len(model.layers) - 1].output_shape[1:], hasSimpleAsLast)
			except AttributeError:
				addLayer(model, model.layers[len(model.layers) - 1].units, hasSimpleAsLast)
		else:
			break

	if not hasSimpleAsLast[0]:
		model.add(tf.keras.layers.Flatten())
	model.add(tf.keras.layers.Dense(7, activation = tf.nn.softmax))#policy value model
	print("Here's the policy model:")
	model.summary()
	model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])
	model.save("models//" + modelName + "//the_policy_champ")
	
	os.mkdir("models//" + modelName + "//trainingData")
	# createTrainingSet(os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + modelName, True)
	
def loadModel(): # User selects model, selected model path is returned
	folderList = os.listdir(os.path.dirname(os.path.realpath(__file__)) + "\\models")
	if folderList:
		print("Models:")
		
		for i, folder in enumerate(folderList):
			print(str(i + 1) + ". " + folder)
			
		while True:
			try:
				modelInd = int(input(("Which model do you want to load?\n> ")))
				if modelInd > len(folderList) or modelInd <= 0:
					print("Value out of range")
				else:
					break
			except ValueError:
				print("Which model do you want to load?\n> ")
		
		if modelInd:
			return os.path.dirname(os.path.realpath(__file__)) + "\\models\\" + folderList[modelInd - 1]
	
def addLayer(model, shape, hasSimpleAsLast): # Adds layer to model currently being created by the user
	userChoice = config.getResponseFromList("Would you like to make a convolutional, or simple layer?", ('c', 's'))
	if userChoice == 'c':
		hasSimpleAsLast[0] = False
		filterNum = config.getIntResponse("How many filters should this layer have?")
		filterDimVert = config.getIntResponse("What should the height of the filter be?")
		filterDimHori = config.getIntResponse("What should the width of the filter be?")
		paddingChoice = config.getResponseFromList("Should the padding type be same (zero padded), or valid (non-zero padded)?", ('s', 'v'))
		model.add(tf.keras.layers.Conv2D(filterNum, (filterDimVert, filterDimHori), input_shape = shape, padding="same" if paddingChoice == 's' else "valid"))
		model.add(tf.keras.layers.BatchNormalization())
		model.add(tf.keras.layers.Activation(config.getResponseFromList("Which activation function should the layer use?", ('elu', 'relu', 'selu', 'sigmoid', 'softplus', 'softmax', 'softsign', 'tanh'))))
	elif userChoice == 's':
		activationDict = {
			"el" : tf.nn.elu,
			"rl" : tf.nn.relu,
			"sl" : tf.nn.selu,
			"sg" : tf.nn.sigmoid,
			"sm" : tf.nn.softmax,
			"sp" : tf.nn.softplus,
			"ss" : tf.nn.softsign,
			"tn" : tf.nn.tanh
		}
		nuerons = config.getIntResponse("How many neurons should this layer have?")
		layerActivation = activationDict[config.getResponseFromList("What activation function should the layer use? elu, relu, selu, sigmoid, softplus, softmax, softsign, or tanh?", ('el', 'rl', 'sl', 'sg', 'sm', 'sp', 'ss', 'tn'))]
		if not hasSimpleAsLast[0]:
			model.add(tf.keras.layers.Flatten(input_shape=shape))
		model.add(tf.keras.layers.Dense(nuerons, activation = layerActivation))
		hasSimpleAsLast[0] = True

def autoSelfplay(): # user loads model, function cycles updating training set, creating challenger, and performing showdowns
	modelPath = loadOrCreateModel()

	while True:
		createTrainingSet(modelPath)
		createChallengerPair(modelPath)
		modelShowdown(modelPath)
		
def generationTournament(): # Performs a round robin tournament in which each previous saved champion and current champion play eachother as many times as is stored in the config.selfTournamentShowDownSize variable, shows results and gives user option to save results
	modelPath = loadModel()
	
	champArrayVal = sorted([f for f in os.listdir(modelPath) if os.path.isfile(os.path.join(modelPath, f)) and f[0:12] == "prevChampVal"], key=lambda x: int(x[12:]))
	champArrayPol = sorted([f for f in os.listdir(modelPath) if os.path.isfile(os.path.join(modelPath, f)) and f[0:12] == "prevChampPol"], key=lambda x: int(x[12:]))

	try:
		if len(champArrayPol) != len(champArrayVal):
			raise Exception("Unequal count of Value and Policy Neural Nets")
		else:
			for i in range(len(champArrayVal)):
				if champArrayVal[i][12:] != champArrayPol[i][12:]:
					raise Exception("Neural nets are missing from policy or value arrays")
	except Exception as e:
		print("Error: " + str(e))
	
	tournDict = {}
	print("Beginning Tournament!")
	
	for i in range(len(champArrayVal)):
		valNN1 = tf.keras.models.load_model(modelPath + "\\prevChampVal" + str(i + 1))
		polNN1 = tf.keras.models.load_model(modelPath + "\\prevChampPol" + str(i + 1))
		if i < len(champArrayVal):
			for j in range(i + 1, len(champArrayVal)):
				print(str(i + 1) + " vs " + str(j + 1))
				valNN2 = tf.keras.models.load_model(modelPath + "\\prevChampVal" + str(j + 1))
				polNN2 = tf.keras.models.load_model(modelPath + "\\prevChampPol" + str(j + 1))
				
				nn1Wins, nn2Wins, drawCount = head2Head(False, "Gen " + str(i + 1), "Gen " + str(j + 1), valNN1, polNN1, valNN2, polNN2, config.selfTournamentShowDownSize, config.trainingRecursionCount)
				
				tournDict[str(i + 1) + "vs" + str(j + 1)] = {"nn1Wins": nn1Wins, "nn2Wins": nn2Wins, "Draws": drawCount}
		
		print(str(i + 1) + " vs champ") 
		valNN2 = tf.keras.models.load_model(modelPath + "\\the_value_champ")
		polNN2 = tf.keras.models.load_model(modelPath + "\\the_policy_champ")
		
		nn1Wins, nn2Wins, drawCount = head2Head(False, "Gen " + str(i + 1), "Champ", valNN1, polNN1, valNN2, polNN2, config.selfTournamentShowDownSize, config.trainingRecursionCount)
		tournDict[str(i) + "vsChamp"] = {"nn1Wins": nn1Wins, "nn2Wins": nn2Wins, "Draws": drawCount}
	
	print("Completed Tournament! Final Results: ")
	for key, val in tournDict.items():
		print(key + ": " + str(val))
		
	if config.getResponseFromList("Do you wish to save this result?", ('y','n')) == 'y':
		if not os.path.exists(modelPath + "\\selfTournamentResults\\"):
			os.makedirs(modelPath + "\\selfTournamentResults\\")
		_pickle.dump(tournDict, open(modelPath + "\\selfTournamentResults\\bo" + str(config.selfTournamentShowDownSize) + datetime.datetime.now().strftime("%Y-%m-%d-%H-%M"), "wb"))
		
def loadTournamentResults(): # User can select any existing selfplay tournament results
	resultsPath = loadModel() + "\\selfTournamentResults\\"
	if not os.path.exists(resultsPath):
		print("No tournament results exist")
		return
	else:
		resultList = os.listdir(resultsPath)
		for i, fileName in enumerate(resultList):
			print(str(i + 1) + ". " + fileName)
		
		while True:
			try:
				modelInd = int(input(("Which result do you want to load?\n> ")))
				if modelInd > len(resultList) or modelInd <= 0:
					print("Value out of range.")
				else:
					break
			except ValueError:
				print("Try typing a number.")
		
		for key, val in _pickle.load(open(resultsPath + resultList[modelInd - 1], "rb")).items():
			print(key + ": " + str(val))